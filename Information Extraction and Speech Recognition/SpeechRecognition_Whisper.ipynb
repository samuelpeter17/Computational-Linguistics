{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Speech Recognition with Whisper\n",
        "Dartmouth College, LING48, Spring 2023<br>\n",
        "Samuel Peter (samuel.peter.25@dartmouth.edu)\n",
        "\n",
        "[Whisper](https://github.com/openai/whisper) is an End-to-End speech recognition system from OpenAI."
      ],
      "metadata": {
        "id": "DJ7TgJmhOvhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "m75CNMmZIKMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077762d8-a71b-4162-90b4-9ee04f98ec7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en4GcxdEHXDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9034aae1-0815-40ae-c9d5-3a1aff4cb43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-hu7433fo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-hu7433fo\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.59.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper==20231117) (8.10.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.7.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.42.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "HztRFNp4H2sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "cvdJruUIIDXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\", device=DEVICE)\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ],
      "metadata": {
        "id": "AWQSQ9g6IEN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf31ecff-c5e6-4258-fa8a-fd2f3136ac20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is multilingual and has 71,825,920 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio = whisper.load_audio(\"/content/drive/My Drive/whisper-test/asr-otherlang.m4a\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)"
      ],
      "metadata": {
        "id": "jZZFkJR7IHhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, probs = model.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True, fp16 = False)\n",
        "result = whisper.decode(model, mel, options)\n",
        "print(result.text)"
      ],
      "metadata": {
        "id": "i3MPG1r8IZMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66de1c01-08c4-4ffc-b753-b8cdd2debf48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: la\n",
            "Hello, I'm Samuel. In my time I free myself to sing the football. But if I ask my favorite player in Manchester City, ask my club favorite. I will be singing in spring and I can't wait to be part of the football live.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"/content/drive/My Drive/whisper-test/asr-otherlang.m4a\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "uEGqXWvNJs3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67f5c86-27c5-45c8-cca3-c2bf5682800b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hola, soy Samuel, en mi tiempo libre mi encanta hugar al football, mesi es mi huagador favorito i al Manchester City es mi club favorito. Viaho apralga en primavera i no puedo esperar a ver mi primer partido del football en vivo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxDMAbpDn_tK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}