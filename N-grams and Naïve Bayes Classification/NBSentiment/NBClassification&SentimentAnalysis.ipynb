{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO6CaG5I95qX"
      },
      "source": [
        "# Naïve Bayes Classification and Sentiment Analysis\n",
        "Dartmouth College, LING48, Spring 2024<br>\n",
        "Samuel Peter (samuel.peter.25[link text](https://)@dartmouth.edu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do4rReRL-CC3"
      },
      "source": [
        "# Import libraries\n",
        "import itertools\n",
        "import collections\n",
        "from nltk import word_tokenize\n",
        "import nltk.classify.util\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "from nltk.metrics.scores import precision, recall, f_measure\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "import gdown"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo1FBNHw-tF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6373e041-8f1f-4966-d66e-10d41d42d708"
      },
      "source": [
        "# Download the 'punkt' library for NLTK\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59NSDuDO-INm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d510f7d-f392-4169-c2a3-522b9ab47f8c"
      },
      "source": [
        "# Download files\n",
        "url = \"https://drive.google.com/uc?id=1aQRJ5htEHZMmajz-HAcyJLVaYw_X-yOw\"\n",
        "output = 'hw4-nb-files.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "!unzip -jo $output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aQRJ5htEHZMmajz-HAcyJLVaYw_X-yOw\n",
            "To: /content/hw4-nb-files.zip\n",
            "100%|██████████| 430k/430k [00:00<00:00, 18.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  hw4-nb-files.zip\n",
            "  inflating: amazon-neg.txt          \n",
            "  inflating: amazon-pos.txt          \n",
            "  inflating: google-neg.txt          \n",
            "  inflating: google-pos.txt          \n",
            "  inflating: mini-movie-reviews.txt  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHJs3kQ6-E0G"
      },
      "source": [
        "# Function to construct a bag of words with both unigrams and bigrams\n",
        "# https://streamhacker.com/2010/05/24/\n",
        "# text-classification-sentiment-analysis-stopwords-collocations/\n",
        "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
        "\n",
        "  bigram_finder = BigramCollocationFinder.from_words(words)\n",
        "  bigrams = bigram_finder.nbest(score_fn, n)\n",
        "\n",
        "  tupledWords = []\n",
        "  for w in words:\n",
        "    tempList = []\n",
        "    tempList.append(w)\n",
        "    tempTuple = tuple(tempList)\n",
        "    tupledWords.append(tempTuple)\n",
        "\n",
        "  return dict([(ngram, True) for ngram in itertools.chain(tupledWords, bigrams)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Method: runNBTest - method to run a Naive Bayes Sentiment Analysis\n",
        "#Parameters:  filenamePos : The file that has the positive reviews\n",
        "#             filenameNeg : The file that has the negative reviews\n",
        "#             cutoff      : The percentage of reviews that should be used for the training set (e.g.0.8,0.7,0.9)\n",
        "#             numFeats    : The number of \"most informative features\" that should be presented at the end of the analysis\n",
        "def runNBTest(filenamePos, filenameNeg, cutoff, numFeats):\n",
        "  # We will store the negative and positive reviews here\n",
        "  posReviewsText = []\n",
        "  negReviewsText = []\n",
        "\n",
        "  # Open the file containing the positive reviews\n",
        "  file = open(filenamePos, \"r\")\n",
        "  fileLines = file.readlines()\n",
        "  # Go through the file and put the text of the reviews in the correct list.\n",
        "  for l in fileLines:\n",
        "    tempLine = l.split(\"\\n\")\n",
        "    posReviewsText.append(tempLine[0])\n",
        "\n",
        "  # Open the file containing the negative reviews\n",
        "  file = open(filenameNeg, \"r\")\n",
        "  fileLines = file.readlines()\n",
        "  # Go through the file and put the text of the reviews in the correct list.\n",
        "  for l in fileLines:\n",
        "    tempLine = l.split(\"\\n\")\n",
        "    negReviewsText.append(tempLine[0])\n",
        "\n",
        "  # This will contain the bag-of-words\n",
        "  # for positive and negative reviews.\n",
        "  negfeats = []\n",
        "  posfeats = []\n",
        "\n",
        "  # for every positive review:\n",
        "  # (1) tokenize it, (2) extract the bag-of-words as\n",
        "  # features, and (3) append it to the positive features.\n",
        "  for f in posReviewsText:\n",
        "    tokens = word_tokenize(f)\n",
        "    wordFeats = bigram_word_feats(tokens)\n",
        "    posfeats.append((wordFeats, 'pos'))\n",
        "\n",
        "  # for every negative review:\n",
        "  # (1) tokenize it, (2) extract the bag-of-words as\n",
        "  # features, and (3) append it to the negative features.\n",
        "  for f in negReviewsText:\n",
        "    tokens = word_tokenize(f)\n",
        "    wordFeats = bigram_word_feats(tokens)\n",
        "    negfeats.append((wordFeats, 'neg'))\n",
        "\n",
        "  # Get the number of elements that\n",
        "  # will be in the training set.\n",
        "  negcutoff = int(len(negfeats)*cutoff) # The number has to be an entire integer so that we can use it as an index\n",
        "  poscutoff = int(len(posfeats)*cutoff)\n",
        "\n",
        "  # Make the training and testing sets.\n",
        "  trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
        "  testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
        "  print('train on ' + str(len(trainfeats)) + ' instances, test on ' + str(len(testfeats)) + ' instances')\n",
        "\n",
        "  # Make a classifier based on the training features.\n",
        "  classifier = NaiveBayesClassifier.train(trainfeats)\n",
        "\n",
        "  # create two blank dictionaries that will contain\n",
        "  # the goldLabels and the predictedLabels\n",
        "  goldLabels = collections.defaultdict(set)\n",
        "  predictedLabels = collections.defaultdict(set)\n",
        "\n",
        "  # get the gold labels and the model predictions\n",
        "  # for every item in the test set and put the\n",
        "  # labels and the predictions in a Python dictionary\n",
        "  for i, (feats, label) in enumerate(testfeats):\n",
        "      # add the gold labels to the goldLabels dictionary\n",
        "      goldLabels[label].add(i)\n",
        "      # get the model's predictions (the \"observed\" labels)\n",
        "      observed = classifier.classify(feats)\n",
        "      # add the model predictions to the predictedLabels dictionary\n",
        "      predictedLabels[observed].add(i)\n",
        "\n",
        "  # Calculate the precision ,recall and\n",
        "  # F for the positive and negative sets.\n",
        "\n",
        "  posPrecision = precision(goldLabels['pos'], predictedLabels['pos'])\n",
        "  posRecall    = recall(goldLabels['pos'], predictedLabels['pos'])\n",
        "  negPrecision = precision(goldLabels['neg'], predictedLabels['neg'])\n",
        "  negRecall    = recall(goldLabels['neg'], predictedLabels['neg'])\n",
        "  negF         = f_measure(goldLabels['neg'], predictedLabels['neg'])\n",
        "  posF         = f_measure(goldLabels['pos'], predictedLabels['pos'])\n",
        "\n",
        "\n",
        "  # Print the accuracy, precisions, recalls and F values.\n",
        "  print('accuracy:      ' + str(nltk.classify.util.accuracy(classifier, testfeats)))\n",
        "  print('pos precision: ' + str(posPrecision))\n",
        "  print('pos recall:    ' + str(posRecall))\n",
        "  print('neg precision: ' + str(negPrecision))\n",
        "  print('neg recall:    ' + str(negRecall) )\n",
        "  print('neg F-measure: ' + str(negF))\n",
        "  print('pos F-measure: ' + str(posF))\n",
        "\n",
        "  # Print the most informative features.\n",
        "  classifier.show_most_informative_features(n=numFeats)"
      ],
      "metadata": {
        "id": "Ag8TbTzZjVNb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== AMAZON ===\")\n",
        "runNBTest(\"amazon-pos.txt\", \"amazon-neg.txt\", 0.8, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqm030XrnzPq",
        "outputId": "930ae8da-c9c9-480a-bedf-cff90616d80b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AMAZON ===\n",
            "train on 800 instances, test on 200 instances\n",
            "accuracy:      0.89\n",
            "pos precision: 0.90625\n",
            "pos recall:    0.87\n",
            "neg precision: 0.875\n",
            "neg recall:    0.91\n",
            "neg F-measure: 0.892156862745098\n",
            "pos F-measure: 0.8877551020408163\n",
            "Most Informative Features\n",
            "              ('Great',) = True              pos : neg    =     40.3 : 1.0\n",
            "               ('nice',) = True              pos : neg    =     13.0 : 1.0\n",
            "              ('smart',) = True              pos : neg    =     12.3 : 1.0\n",
            "         ('people', ',') = True              pos : neg    =     11.7 : 1.0\n",
            "              ('learn',) = True              pos : neg    =     11.0 : 1.0\n",
            "      ('opportunities',) = True              pos : neg    =      9.8 : 1.0\n",
            "           ('benefits',) = True              pos : neg    =      9.7 : 1.0\n",
            "         ('to', 'learn') = True              pos : neg    =      9.0 : 1.0\n",
            "            ('balance',) = True              neg : pos    =      8.8 : 1.0\n",
            "                ('Not',) = True              neg : pos    =      7.8 : 1.0\n",
            "          ('You', 'get') = True              pos : neg    =      7.7 : 1.0\n",
            "               ('does',) = True              neg : pos    =      7.7 : 1.0\n",
            "  ('opportunity', 'for') = True              pos : neg    =      7.7 : 1.0\n",
            "               ('rate',) = True              neg : pos    =      7.7 : 1.0\n",
            "                 ('No',) = True              neg : pos    =      7.4 : 1.0\n",
            "               ('Good',) = True              pos : neg    =      7.0 : 1.0\n",
            "          ('a', 'great') = True              pos : neg    =      7.0 : 1.0\n",
            "                ('fun',) = True              pos : neg    =      7.0 : 1.0\n",
            "           ('get', 'to') = True              pos : neg    =      7.0 : 1.0\n",
            "       ('long', 'hours') = True              neg : pos    =      7.0 : 1.0\n",
            "        ('work', 'with') = True              pos : neg    =      7.0 : 1.0\n",
            "     ('life', 'balance') = True              neg : pos    =      6.6 : 1.0\n",
            "          ('.', 'Great') = True              pos : neg    =      6.3 : 1.0\n",
            "             ('decent',) = True              pos : neg    =      6.3 : 1.0\n",
            "             ('expect',) = True              neg : pos    =      6.3 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== GOOGLE ===\")\n",
        "runNBTest(\"google-pos.txt\", \"google-neg.txt\", 0.8, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_HlRFrH-aMi",
        "outputId": "6ff1058b-d352-4369-c4c4-fc53383ea9cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GOOGLE ===\n",
            "train on 800 instances, test on 200 instances\n",
            "accuracy:      0.885\n",
            "pos precision: 0.9230769230769231\n",
            "pos recall:    0.84\n",
            "neg precision: 0.8532110091743119\n",
            "neg recall:    0.93\n",
            "neg F-measure: 0.8899521531100479\n",
            "pos F-measure: 0.8795811518324608\n",
            "Most Informative Features\n",
            "              ('Great',) = True              pos : neg    =     29.8 : 1.0\n",
            "              ('perks',) = True              pos : neg    =     25.4 : 1.0\n",
            "               ('free',) = True              pos : neg    =     21.0 : 1.0\n",
            "            ('amazing',) = True              pos : neg    =     17.7 : 1.0\n",
            "          ('hard', 'to') = True              neg : pos    =     15.7 : 1.0\n",
            "               ('Good',) = True              pos : neg    =     15.0 : 1.0\n",
            "           ('can', 'be') = True              neg : pos    =     14.2 : 1.0\n",
            "          ('sometimes',) = True              neg : pos    =     13.7 : 1.0\n",
            "        ('interesting',) = True              pos : neg    =     13.0 : 1.0\n",
            "           ('food', ',') = True              pos : neg    =     12.6 : 1.0\n",
            "          ('difficult',) = True              neg : pos    =     12.3 : 1.0\n",
            "              ('times',) = True              neg : pos    =     12.3 : 1.0\n",
            "                ('fun',) = True              pos : neg    =     10.2 : 1.0\n",
            "           ('politics',) = True              neg : pos    =      9.7 : 1.0\n",
            "           ('benefits',) = True              pos : neg    =      9.5 : 1.0\n",
            "            ('awesome',) = True              pos : neg    =      9.0 : 1.0\n",
            "        ('culture', ',') = True              pos : neg    =      9.0 : 1.0\n",
            "     ('and', 'benefits') = True              pos : neg    =      8.3 : 1.0\n",
            "    ('environment', ',') = True              pos : neg    =      8.3 : 1.0\n",
            "            ('nothing',) = True              neg : pos    =      8.3 : 1.0\n",
            "               ('food',) = True              pos : neg    =      8.2 : 1.0\n",
            "               ('Free',) = True              pos : neg    =      7.8 : 1.0\n",
            "                ('not',) = True              neg : pos    =      7.8 : 1.0\n",
            "             (\"'s\", 'a') = True              neg : pos    =      7.7 : 1.0\n",
            "       ('organization',) = True              neg : pos    =      7.7 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQtF9x92D3ur"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}